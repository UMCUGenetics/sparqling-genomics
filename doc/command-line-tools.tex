
\chapter{Command-line programs}

  The project provides programs to create a complete pipeline including
  data conversion, data importing and data exploration.  The tasks we can
  perform with the command-line programs are:
  \begin{itemize}
    \item Extract triples from VCF files;
    \item Extract triples from tabular data files;
    \item Push data to a SPARQL endpoint.
  \end{itemize}

\section{Preparing variant call data with \texttt{vcf2rdf}}
\label{sec:vcf2rdf}

  Obtaining variants from sequenced data is a task of so called
  \emph{variant callers}.  These programs often output the variants they found
  in the \emph{Variant Call Format} (VCF).  Before we can use the data described
  in this format, we need to extract \emph{knowledge} (in the form of triples)
  from it.

  The \texttt{vcf2rdf} program does exactly this, by converting a VCF file
  into an RDF format.  In section \ref{sec:curl} {\color{LinkGray}`\nameref{sec:curl}%
  '} we describe how to import the data produced by \texttt{vcf2rdf} in the
  database.

\subsection{Knowledge extracted by \texttt{vcf2rdf}}

  The program treats the VCF as its own ontology.  It uses the VCF header as
  a guide.  All fields described in the header of the VCF file will be
  translated into triples.

  In addition to the knowledge from the VCF file, \texttt{vcf2rdf} stores the
  following metadata:

    \begin{table}[H]
    \begin{tabularx}{\textwidth}{ l l l L }
      \headrow
      \textbf{Subject} & \textbf{Predicate} & \textbf{Object}
      & \textbf{Description}\\
      \evenrow
      :Origin & rdf:type & owl:Class
      & \texttt{:Origin} is used to identify a data origin (which
      is usually a file).\\
      \oddrow
      :Sample & rdf:type & owl:Class
      & \texttt{:Sample} is used to identify a sample name.\\
      \evenrow
      :filename & rdf:type & xsd:string
      & \texttt{:filename} contains the path to the file that \texttt{:Origin}
      represents.\\
      \oddrow
      :convertedBy & rdf:type & owl:AnnotationProperty
      & \texttt{:convertedBy} is used to identify the program that performed
      the VCF->RDF conversion.\\
      \evenrow
      :foundIn & rdf:type & owl:AnnotationProperty
      & \texttt{:foundIn} relates the \texttt{:Origin} to a \texttt{:Sample}.\\
    \end{tabularx}
    \caption{\small The additional triple patterns described by \texttt{vcf2rdf}.}
    \label{table:vcf2rdf-ontology}
  \end{table}

  The following snippet is an example of the extra data in Turtle-format:

\begin{siderules}
\begin{verbatim}
<http://rdf.umcutrecht.nl/vcf2rdf/14f2b609b>
    :convertedBy :vcf2rdf ;
    :filename "clone_ref_tumor.vcf.gz"^^xsd:string ;
    a :Origin .

sample:CLONE_REF
    :foundIn <http://rdf.umcutrecht.nl/vcf2rdf/14f2b609b3> ;
    a :Sample .

sample:CLONE_TUMOR
    :foundIn <http://rdf.umcutrecht.nl/vcf2rdf/14f2b609b3> ;
    a :Sample .
\end{verbatim}
\end{siderules}

\subsection{Example usage}

\begin{siderules}
\begin{verbatim}
vcf2rdf -i /path/to/my/variants.vcf > /path/to/my/variants.ttl
\end{verbatim}
\end{siderules}

\subsection{Run-time properties}

  Depending on the serialization format, the program typically uses from two megabytes
  (in \texttt{ntriples} mode), to multiple times the size of the input VCF
  (in \texttt{turtle} mode).

  The \texttt{ntriples} mode can output triples as soon as they are formed, while the
  \texttt{turtle} mode waits until all triples are known, so that it can output them
  efficiently, producing compact output at the cost of using more memory.

  We recommend using the \texttt{ntriples} format for large input files, and
  \texttt{turtle} for small input files.

\section{Preparing tabular data with \texttt{table2rdf}}
\label{sec:table2rdf}

  Data that can be represented as a table, like comma-separated values (CSV)
  or BED files, can be imported using \texttt{table2rdf}.  The column headers
  are used as predicates, and each row gets a unique row ID.  Non-alphanumeric
  characters in the header line are replaced by underscores, and all characters
  are replaced by their lowercase equivalent to make a consistent scheme for
  predicates.

  When the file does not contain a header line, one can be specified using the
  \texttt{-{}-header-line} argument.  When using this command-line argument, the
  delimiter must be a semicolon (\texttt{;}).

\subsection{Transformers}

  Furthermore, \texttt{table2rdf} knows nothing about ontologies.  So when the
  input table has a column ``Chromosome'', by default \texttt{table2rdf} will
  treat these cells as literal values.  Sometimes we would like to express a
  column as an \emph{individual} in RDF.  To do that, a transformer can be
  used.  An example follows.

  Take the following input file:
\begin{siderules}
\begin{verbatim}
$ cat test.tsv
Chromosome      Position
chr1    1500000
chrMT   11000
\end{verbatim}
\end{siderules}

  Running \texttt{table2rdf} with its default settings will produce:

\begin{siderules}
\begin{verbatim}
$ table2rdf -i test.tsv
...
<http://rdf.umcutrecht.nl/table2rdf/Column/...-R0000000000>
    sg:originatedFrom <http://rdf.umcutrecht.nl/...> ;
    col:chromosome "chr1"^^xsd:string ;
    col:position 1500000 ;
    a :Row .

<http://rdf.umcutrecht.nl/table2rdf/Column/...-R0000000001>
    sg:originatedFrom <http://rdf.umcutrecht.nl/...> ;
    col:chromosome "chrMT"^^xsd:string ;
    col:position 11000 ;
    a :Row .
...
\end{verbatim}
\end{siderules}

  When we know that the chromosomes refer to items in an ontology, like
  \href{<http://rdf.biosemantics.org/data/genomeassemblies/hg19>}%
  {http://rdf.biosemantics.org/data/genomeassemblies/hg19}, it would be better
  if \texttt{table2rdf} would use that ontology to describe the chromosomes.

  To do so, we can use the \texttt{-{}-transform} option, or \texttt{-t} for
  short:

\begin{siderules}
\begin{verbatim}
$ table2rdf     \
    -i test.tsv \
    -t Chromosome=http://rdf.biosemantics.org/data/genomeassemblies/hg19#
...
@prefix p0000000000: <http://rdf.biosemantics.org/data/genomeassemblies/hg19#> .
...
<http://rdf.umcutrecht.nl/table2rdf/Column/...-R0000000000>
    sg:originatedFrom <http://rdf.umcutrecht.nl/...> ;
    col:chromosome p0000000000:chr1 ;
    col:position 1500000 ;
    a :Row .

<http://rdf.umcutrecht.nl/table2rdf/Column/...-R0000000001>
    sg:originatedFrom <http://rdf.umcutrecht.nl/...> ;
    col:chromosome p0000000000:chrMT ;
    col:position 11000 ;
    a :Row .
...
\end{verbatim}
\end{siderules}

  After the transformation, the output produced by \texttt{table2rdf} uses
  URIs pointing to the ontology instead of literal values for chromosomes.

\subsection{Knowledge extracted by \texttt{table2rdf}}

  The \texttt{table2rdf} program extracts all fields in the table.  In addition
  to the knowledge from the table file, \texttt{table2rdf} stores the following
  metadata:

  \begin{table}[H]
    \begin{tabularx}{\textwidth}{ l l l L }
      \headrow
      \textbf{Subject} & \textbf{Predicate} & \textbf{Object}
      & \textbf{Description}\\
      \evenrow
      :Origin & rdf:type & owl:Class
      & \texttt{:Origin} is used to identify a data origin (which
      is usually a file).\\
      \oddrow
      :Sample & rdf:type & owl:Class
      & \texttt{:Sample} is used to identify a sample name.\\
      \evenrow
      :filename & rdf:type & xsd:string
      & \texttt{:filename} contains the path to the file that \texttt{:Origin}
      represents.\\
      \oddrow
      :convertedBy & rdf:type & owl:AnnotationProperty
      & \texttt{:convertedBy} is used to identify the program that performed
      the VCF->RDF conversion.\\
      \evenrow
      :foundIn & rdf:type & owl:AnnotationProperty
      & \texttt{:foundIn} relates the \texttt{:Origin} to a \texttt{:Sample}.\\
    \end{tabularx}
    \caption{\small The additional triple patterns described by \texttt{table2rdf}.}
    \label{table:table2rdf-ontology}
  \end{table}

  The following snippet is an example of the extra data in Turtle-format:

  \begin{siderules}
\begin{verbatim}
<http://rdf.umcutrecht.nl/table2rdf/1jka8923i4>
    :convertedBy :table2rdf ;
    :filename "grch37.bed"^^xsd:string ;
    a :Origin .

sample:grch37
    :foundIn <http://rdf.umcutrecht.nl/table2rdf/1jka8923i4> ;
    a :Sample .
\end{verbatim}
\end{siderules}

\subsection{Example usage}

\begin{siderules}
\begin{verbatim}
table2rdf -i /path/to/my/table.tsv > /path/to/my/table.ttl
\end{verbatim}
\end{siderules}

\section{Converting MySQL data to RDF with \texttt{table2rdf}}

  Relational databases store data in tables.  With \texttt{table2rdf} we
  can oftentimes convert the data in a single go to RDF triples.  The following
  example extracts the \texttt{regions} table from a MySQL server in a database
  called \texttt{example}.

\begin{siderules}
\begin{verbatim}
mysql --host=127.0.0.1 -e "SELECT * FROM example.regions" \
      --batch | table2rdf --stdin -O ntriples > regions.n3
\end{verbatim}
\end{siderules}

  The \texttt{mysql} command outputs the table in tab-delimited form when using
  the \texttt{-{}-batch} argument, which is the default input type for
  \texttt{table2rdf}.  To accept input from a UNIX pipe \texttt{table2rdf} must
  be invoked with the \texttt{-{}-stdin} argument.

%% \section{Preparing sequence data with \texttt{fasta2rdf}}
%% \label{sec:fasta2rdf}

%%   Resources like pre-composed reference genomes are often distributed in the
%%   FASTA file format.  The \texttt{fasta2rdf} program generates RDF that
%%   describes each nucleotide, its position (where the first nucleotide is at
%%   position 1, not 0), and to which sequence the nucleotide belongs.

%%   Its main aim is to describe a sequence to allow for querying the sequence
%%   context of a variant.

%% \subsection{Knowledge extracted by \texttt{fasta2rdf}}

%%   The \texttt{fasta2rdf} program extracts a nucleotide and describes it along
%%   with its position in the sequence.

%%   In addition to the knowledge from the FASTA file, \texttt{fasta2rdf} stores the
%%   following metadata:

%%   \begin{table}[H]
%%     \begin{tabularx}{\textwidth}{ l l l L }
%%       \headrow
%%       \textbf{Subject} & \textbf{Predicate} & \textbf{Object}
%%       & \textbf{Description}\\
%%       \evenrow
%%       :Origin & rdf:type & owl:Class
%%       & \texttt{:Origin} is used to identify a data origin (which
%%       is usually a file).\\
%%       \oddrow
%%       :Sample & rdf:type & owl:Class
%%       & \texttt{:Sample} is used to identify a sample name.\\
%%       \evenrow
%%       :Sequence & rdf:type & owl:Class
%%       & \texttt{:Sequence} is used to identify a sequence within the file.
%%       This is typically a chromosome or contig\\
%%       \oddrow
%%       :filename & rdf:type & xsd:string
%%       & \texttt{:filename} contains the path to the file that \texttt{:Origin}
%%       represents.\\
%%       \evenrow
%%       :convertedBy & rdf:type & owl:AnnotationProperty
%%       & \texttt{:convertedBy} is used to identify the program that performed
%%       the VCF->RDF conversion.\\
%%       \oddrow
%%       :foundIn & rdf:type & owl:AnnotationProperty
%%       & \texttt{:foundIn} relates the \texttt{:Origin} to a \texttt{:Sample}.\\
%%     \end{tabularx}
%%     \caption{\small The additional triple patterns described by \texttt{fasta2rdf}.}
%%     \label{table:fasta2rdf-ontology}
%%   \end{table}

%%   The following snippet is an example of the extra data in Turtle-format:

%%   \begin{siderules}
%% \begin{verbatim}
%% <http://rdf.umcutrecht.nl/fasta2rdf/14f2b609b>
%%     :convertedBy :vcf2rdf ;
%%     :filename "grch37.fasta.gz"^^xsd:string ;
%%     a :Origin .

%% sample:grch37
%%     :foundIn <http://rdf.umcutrecht.nl/fasta2rdf/14f2b609b3> ;
%%     a :Sample .

%% sample:CLONE_TUMOR
%%     :foundIn <http://rdf.umcutrecht.nl/fasta2rdf/14f2b609b3> ;
%%     a :Sample .
%% \end{verbatim}
%% \end{siderules}

\section{Importing data with \texttt{curl}}
\label{sec:curl}

  To load RDF data into a triple store (our database), we can use \texttt{curl}.

  The triple stores typically store data in \emph{graphs}.  One triple store
  can host multiple graphs, so we must tell the triple store which graph we
  would like to add the data to.

\subsection{Example usage}

% Other types: application/n-triples
\begin{siderules}
\begin{verbatim}
curl -X POST                                                 \
     -H "Content-Type: text/turtle"                          \
     -T /path/to/variants.ttl                                \
     -G <endpoint URL>                                       \
     --digest -u <username>:<password>                       \
     --data-urlencode graph=http://example/graph
\end{verbatim}
\end{siderules}

\subsubsection{Virtuoso example}

\begin{sloppypar}
The following example inserts the file \texttt{vcf2rdf-variants.ttl} into
a graph called \texttt{http://example/graph} in a Virtuoso endpoint at
\url{http://127.0.0.1:8890} with the username \texttt{dba} and
password \texttt{qwerty}.
\end{sloppypar}

\begin{siderules}
\begin{verbatim}
curl -X POST                                                 \
     -H "Content-Type: text/turtle"                          \
     -T vcf2rdf-variants.ttl                                 \
     -G http://127.0.0.1:8890/sparql-graph-crud-auth         \
     --digest -u dba:qwerty                                  \
     --data-urlencode graph=http://example/graph
\end{verbatim}
\end{siderules}

\subsubsection{4store example}

Similar to the Virtuoso example, for \texttt{4store} the command looks like
this:

\begin{siderules}
\begin{verbatim}
curl -X POST                                                 \
     -H "Content-Type: text/turtle"                          \
     -T vcf2rdf-variants.ttl                                 \
     -G http://127.0.0.1:8080/data/http://example/graph
\end{verbatim}
\end{siderules}

Notice that \texttt{4store} does not provide an authentication mechanism.

\subsubsection{Sending \texttt{gzip}-compressed data}

  When the RDF file is compressed with \texttt{gzip}, extra HTTP headers must
  be added to the \texttt{curl} command:
\begin{siderules}
\begin{verbatim}
curl -X POST                                                 \
     -H "Content-Type: text/turtle"                          \
     -H "Transfer-Encoding: chunked"                         \
     -H "Content-Encoding: gzip"                             \
     ...
\end{verbatim}
\end{siderules}
