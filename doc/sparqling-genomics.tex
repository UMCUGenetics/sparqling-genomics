\documentclass[11pt,a4paper,oneside]{book}
\usepackage{umcu}
\title{SPARQLing genomics}
\author{Roel Janssen}

\begin{document}

\begin{titlepage}
  \topskip0pt
  \vspace*{\fill}
  \begin{center}
    \includegraphics[width=0.75\textwidth]{figures/logo.pdf}
    %\Huge SPARQLing genomics
    \rule{0.75\textwidth}{1.0pt}~\\
    %\Large Roel Janssen~\\~\\
    \url{https://github.com/UMCUGenetics/sparqling-genomics}~\\
    \large v0.99.3, \today{}
    % Put it a little bit above the center of the page.
    ~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\~\\
  \end{center}
  \topskip0pt
  \vspace*{\fill}

  \thispagestyle{empty}
\end{titlepage}

\setcounter{page}{1}
\pagenumbering{roman}
\hypersetup{linkcolor=black}
\tableofcontents
\newpage{}
\hypersetup{linkcolor=LinkGray}
\setcounter{page}{1}
\pagenumbering{arabic}

\input{introduction}

\chapter{Command-line programs}

  The project provides programs to create a complete pipeline including
  data conversion, data importing and data exploration.  The tasks we can
  perform with the command-line programs are:
  \begin{itemize}
    \item Extract triples from VCF files;
    \item Extract triples from tabular data files;
    \item Push data to a SPARQL endpoint.
  \end{itemize}

\section{Preparing variant call data with \texttt{vcf2rdf}}
\label{sec:vcf2rdf}

  Obtaining variants from sequenced data is a task of so called
  \emph{variant callers}.  These programs often output the variants they found
  in the \emph{Variant Call Format} (VCF).  Before we can use the data described
  in this format, we need to extract \emph{knowledge} (in the form of triples)
  from it.

  The \texttt{vcf2rdf} program does exactly this, by converting a VCF file
  into an RDF format.  In section \ref{sec:curl} {\color{LinkGray}`\nameref{sec:curl}%
  '} we describe how to import the data produced by \texttt{vcf2rdf} in the
  database.

\subsection{Knowledge extracted by \texttt{vcf2rdf}}

  The program treats the VCF as its own ontology.  It uses the VCF header as
  a guide.  All fields described in the header of the VCF file will be
  translated into triples.

  In addition to the knowledge from the VCF file, \texttt{vcf2rdf} stores the
  following metadata:

    \begin{table}[H]
    \begin{tabularx}{\textwidth}{ l l l L }
      \headrow
      \textbf{Subject} & \textbf{Predicate} & \textbf{Object}
      & \textbf{Description}\\
      \evenrow
      :Origin & rdf:type & owl:Class
      & \texttt{:Origin} is used to identify a data origin (which
      is usually a file).\\
      \oddrow
      :Sample & rdf:type & owl:Class
      & \texttt{:Sample} is used to identify a sample name.\\
      \evenrow
      :filename & rdf:type & xsd:string
      & \texttt{:filename} contains the path to the file that \texttt{:Origin}
      represents.\\
      \oddrow
      :convertedBy & rdf:type & owl:AnnotationProperty
      & \texttt{:convertedBy} is used to identify the program that performed
      the VCF->RDF conversion.\\
      \evenrow
      :foundIn & rdf:type & owl:AnnotationProperty
      & \texttt{:foundIn} relates the \texttt{:Origin} to a \texttt{:Sample}.\\
    \end{tabularx}
    \caption{\small The additional triple patterns described by \texttt{vcf2rdf}.}
    \label{table:vcf2rdf-ontology}
  \end{table}

  The following snippet is an example of the extra data in Turtle-format:

\begin{siderules}
\begin{verbatim}
<http://rdf.umcutrecht.nl/vcf2rdf/14f2b609b>
    :convertedBy :vcf2rdf ;
    :filename "clone_ref_tumor.vcf.gz"^^xsd:string ;
    a :Origin .

sample:CLONE_REF
    :foundIn <http://rdf.umcutrecht.nl/vcf2rdf/14f2b609b3> ;
    a :Sample .

sample:CLONE_TUMOR
    :foundIn <http://rdf.umcutrecht.nl/vcf2rdf/14f2b609b3> ;
    a :Sample .
\end{verbatim}
\end{siderules}

\subsection{Example usage}

\begin{siderules}
\begin{verbatim}
vcf2rdf -i /path/to/my/variants.vcf > /path/to/my/variants.ttl
\end{verbatim}
\end{siderules}

\subsection{Run-time properties}

  Depending on the serialization format, the program typically uses from two megabytes
  (in \texttt{ntriples} mode), to multiple times the size of the input VCF
  (in \texttt{turtle} mode).

  The \texttt{ntriples} mode can output triples as soon as they are formed, while the
  \texttt{turtle} mode waits until all triples are known, so that it can output them
  efficiently, producing compact output at the cost of using more memory.

  We recommend using the \texttt{ntriples} format for large input files, and
  \texttt{turtle} for small input files.

\section{Preparing tabular data with \texttt{table2rdf}}
\label{sec:table2rdf}

  Data that can be represented as a table, like comma-separated values (CSV)
  or BED files, can be imported using \texttt{table2rdf}.  The column headers
  are used as predicates, and each row gets a unique row ID.  Non-alphanumeric
  characters in the header line are replaced by underscores, and all characters
  are replaced by their lowercase equivalent to make a consistent scheme for
  predicates.

  When the file does not contain a header line, one can be specified using the
  \texttt{-{}-header-line} argument.  When using this command-line argument, the
  delimiter must be a semicolon (\texttt{;}).

\subsection{Knowledge extracted by \texttt{table2rdf}}

  The \texttt{table2rdf} program extracts all fields in the table.  In addition
  to the knowledge from the table file, \texttt{table2rdf} stores the following
  metadata:

  \begin{table}[H]
    \begin{tabularx}{\textwidth}{ l l l L }
      \headrow
      \textbf{Subject} & \textbf{Predicate} & \textbf{Object}
      & \textbf{Description}\\
      \evenrow
      :Origin & rdf:type & owl:Class
      & \texttt{:Origin} is used to identify a data origin (which
      is usually a file).\\
      \oddrow
      :Sample & rdf:type & owl:Class
      & \texttt{:Sample} is used to identify a sample name.\\
      \evenrow
      :filename & rdf:type & xsd:string
      & \texttt{:filename} contains the path to the file that \texttt{:Origin}
      represents.\\
      \oddrow
      :convertedBy & rdf:type & owl:AnnotationProperty
      & \texttt{:convertedBy} is used to identify the program that performed
      the VCF->RDF conversion.\\
      \evenrow
      :foundIn & rdf:type & owl:AnnotationProperty
      & \texttt{:foundIn} relates the \texttt{:Origin} to a \texttt{:Sample}.\\
    \end{tabularx}
    \caption{\small The additional triple patterns described by \texttt{table2rdf}.}
    \label{table:table2rdf-ontology}
  \end{table}

  The following snippet is an example of the extra data in Turtle-format:

  \begin{siderules}
\begin{verbatim}
<http://rdf.umcutrecht.nl/table2rdf/1jka8923i4>
    :convertedBy :table2rdf ;
    :filename "grch37.bed"^^xsd:string ;
    a :Origin .

sample:grch37
    :foundIn <http://rdf.umcutrecht.nl/table2rdf/1jka8923i4> ;
    a :Sample .
\end{verbatim}
\end{siderules}

\subsection{Example usage}

\begin{siderules}
\begin{verbatim}
table2rdf -i /path/to/my/table.tsv > /path/to/my/table.ttl
\end{verbatim}
\end{siderules}

\section{Converting MySQL data to RDF with \texttt{table2rdf}}

  Relational databases store data in tables.  With \texttt{table2rdf} we
  can oftentimes convert the data in a single go to RDF triples.  The following
  example extracts the \texttt{regions} table from a MySQL server in a database
  called \texttt{example}.

\begin{siderules}
\begin{verbatim}
mysql --host=127.0.0.1 -e "SELECT * FROM example.regions" \
  --batch | table2rdf --stdin -O ntriples > regions.n3
\end{verbatim}
\end{siderules}

  The \texttt{mysql} command outputs the table in tab-delimited form when using
  the \texttt{-{}-batch} argument, which is the default input type for
  \texttt{table2rdf}.  To accept input from a UNIX pipe \texttt{table2rdf} must
  be invoked with the \texttt{-{}-stdin} argument.

%% \section{Preparing sequence data with \texttt{fasta2rdf}}
%% \label{sec:fasta2rdf}

%%   Resources like pre-composed reference genomes are often distributed in the
%%   FASTA file format.  The \texttt{fasta2rdf} program generates RDF that
%%   describes each nucleotide, its position (where the first nucleotide is at
%%   position 1, not 0), and to which sequence the nucleotide belongs.

%%   Its main aim is to describe a sequence to allow for querying the sequence
%%   context of a variant.

%% \subsection{Knowledge extracted by \texttt{fasta2rdf}}

%%   The \texttt{fasta2rdf} program extracts a nucleotide and describes it along
%%   with its position in the sequence.

%%   In addition to the knowledge from the FASTA file, \texttt{fasta2rdf} stores the
%%   following metadata:

%%   \begin{table}[H]
%%     \begin{tabularx}{\textwidth}{ l l l L }
%%       \headrow
%%       \textbf{Subject} & \textbf{Predicate} & \textbf{Object}
%%       & \textbf{Description}\\
%%       \evenrow
%%       :Origin & rdf:type & owl:Class
%%       & \texttt{:Origin} is used to identify a data origin (which
%%       is usually a file).\\
%%       \oddrow
%%       :Sample & rdf:type & owl:Class
%%       & \texttt{:Sample} is used to identify a sample name.\\
%%       \evenrow
%%       :Sequence & rdf:type & owl:Class
%%       & \texttt{:Sequence} is used to identify a sequence within the file.
%%       This is typically a chromosome or contig\\
%%       \oddrow
%%       :filename & rdf:type & xsd:string
%%       & \texttt{:filename} contains the path to the file that \texttt{:Origin}
%%       represents.\\
%%       \evenrow
%%       :convertedBy & rdf:type & owl:AnnotationProperty
%%       & \texttt{:convertedBy} is used to identify the program that performed
%%       the VCF->RDF conversion.\\
%%       \oddrow
%%       :foundIn & rdf:type & owl:AnnotationProperty
%%       & \texttt{:foundIn} relates the \texttt{:Origin} to a \texttt{:Sample}.\\
%%     \end{tabularx}
%%     \caption{\small The additional triple patterns described by \texttt{fasta2rdf}.}
%%     \label{table:fasta2rdf-ontology}
%%   \end{table}

%%   The following snippet is an example of the extra data in Turtle-format:

%%   \begin{siderules}
%% \begin{verbatim}
%% <http://rdf.umcutrecht.nl/fasta2rdf/14f2b609b>
%%     :convertedBy :vcf2rdf ;
%%     :filename "grch37.fasta.gz"^^xsd:string ;
%%     a :Origin .

%% sample:grch37
%%     :foundIn <http://rdf.umcutrecht.nl/fasta2rdf/14f2b609b3> ;
%%     a :Sample .

%% sample:CLONE_TUMOR
%%     :foundIn <http://rdf.umcutrecht.nl/fasta2rdf/14f2b609b3> ;
%%     a :Sample .
%% \end{verbatim}
%% \end{siderules}

\section{Importing data with \texttt{curl}}
\label{sec:curl}

  To load RDF data into a triple store (our database), we can use \texttt{curl}.

  The triple stores typically store data in \emph{graphs}.  One triple store
  can host multiple graphs, so we must tell the triple store which graph we
  would like to add the data to.

\subsection{Example usage}

% Other types: application/n-triples
\begin{siderules}
\begin{verbatim}
curl -X POST                                                 \
     -H Content-Type:text/turtle                             \
     -T /path/to/variants.ttl                                \
     -G <endpoint URL>                                       \
     --digest -u <username>:<password>                       \
     --data-urlencode graph=http://example/graph
\end{verbatim}
\end{siderules}

\chapter{Web interface}
\label{chap:web-interface}

  In addition to the command-line programs, the project provides a web
  interface for prototyping queries, and quick data reporting.  With the
  web interface you can:
  \begin{itemize}
  \item Write and execute SPARQL queries;
  \item Keep track of different SPARQL endpoints.
  \end{itemize}

\section{Running the web interface}

  The web interface can be started using the \texttt{sg-web} command:

\begin{siderules}
\begin{verbatim}
sg-web
\end{verbatim}
\end{siderules}

  By default, it will be accessible on \url{http://localhost:5000}.

\subsection{Configurating connections}

  The first useful step is to configure a connection to a SPARQL endpoint.

  \begin{figure}[h]
    \begin{center}
      \includegraphics[width=1.0\textwidth]{figures/web-connections.png}
    \end{center}
    \caption{The \emph{connections} page enables users to configure accessible
      SPARQL endpoints.  Adding a connection here will provide an option to
      query it on the \emph{query} page.}
    \label{fig:web-connections}
  \end{figure}

  When providing a username and password for a connection, it will attempt
  to connect using \emph{digest authentication}.

\subsection{Executing queries}

  After configuring at least one endpoint, it can be chosen on the \emph{query}
  page to execute a query against it.

  \begin{figure}[h]
    \begin{center}
      \includegraphics[width=1.0\textwidth]{figures/web-query.png}
    \end{center}
    \caption{The \emph{query} page enables users to execute a query against a
      SPARQL endpoint.  The connections configured at the \emph{connections} page
      can be chosen from the drop-down menu.}
    \label{fig:web-query}
  \end{figure}

\chapter{Information retrieval with SPARQL}

  In section \ref{sec:vcf2rdf} {\color{LinkGray}`%
  \nameref{sec:vcf2rdf}'} we discussed how to extract triples from common data
  formats.  In section \ref{sec:curl} {\color{LinkGray}`\nameref{sec:curl}'} we
  discussed how we could insert those triples into a SPARQL endpoint.

  In this section, we will start exploring the inserted data by using a
  query language called \emph{SPARQL}.  Understanding SPARQL will be crucial
  for the integration in your own programs or scripts --- something we will
  discuss in chapter \ref{chap:programming} {\color{LinkGray}%
  `\nameref{chap:programming}'}.

  The queries in the remainder of this chapter can be readily copy/pasted into
  the query editor of the web interface (see chapter \ref{chap:web-interface}
  {\color{LinkGray}`\nameref{chap:web-interface}'}).

\section{Local querying}

  When we request information from a SPARQL endpoint, we are performing a
  \emph{local query} because we request data from a single place.  In our case,
  that is most likely to be our own SPARQL endpoint.

  In contrast to \emph{local querying}, we can also query multiple SPARQL
  endpoints in one go, to combine the information from multiple locations.
  Combining information from multiple SPARQL endpoints is called \emph{federated
    querying}.

  Federated querying is discussed in section \ref{sec:federated-querying}
  {\color{LinkGray}`\nameref{sec:federated-querying}'}.

\subsection{Listing non-empty graphs}
\label{sec:non-empty-graphs}
  Each SPARQL endpoint can host multiple \emph{graphs}.  Each graph can contain
  an independent set of triples.  The following query displays the available
  non-empty graphs in a SPARQL endpoint:

\begin{siderules}
\begin{verbatim}
SELECT DISTINCT ?graph WHERE { GRAPH ?graph { ?s ?p ?o } }
\end{verbatim}
\end{siderules}

Which may yield the following table:

\begin{table}[H]
  \begin{tabularx}{\textwidth}{ L }
    \headrow
    \textbf{graph}\\
    \evenrow
    \texttt{http://example}\\
    \oddrow
    \texttt{http://localuriqaserver/sparql}\\
    \evenrow
    \texttt{http://www.openlinksw.com/schemas/virtrdf\#}\\
    \oddrow
    \texttt{http://www.w3.org/2002/07/owl\#}\\
    \evenrow
    \texttt{http://www.w3.org/ns/ldp\#}\\
  \end{tabularx}
  \caption{\small Results of the query to list non-empty graphs.}
  \label{table:query-output-1}
\end{table}

  The graph names usually look like URLs, like we would encounter them on the
  web.  In fact, not only graph names, but any node that has a symbolic meaning,
  rather than a literal\footnote{Examples of literals are numbers and strings.
    Symbols are nodes that don't have a literal value.} meaning is usually
  written as a URL.  We can go to such a URL with a web browser and might even
  find more information.

\subsection{Querying a specific graph}

  The sooner we can reduce the dataset to query over, the faster the query will
  return with an answer.  One easy way to reduce the size of the dataset is to
  be specific about which graph to query.  This can be achieved using the
  \texttt{FROM} clause in the query.

\begin{siderules}
\begin{verbatim}
SELECT ?s ?p ?o
FROM <graph-name>
WHERE { ?s ?p ?o }
\end{verbatim}
\end{siderules}

  The \texttt{graph-name} must be one of the graphs returned by the query from
  section \ref{sec:non-empty-graphs} {\color{LinkGray}%
    `\nameref{sec:non-empty-graphs}'}.

  Without the \texttt{FROM} clause, the RDF store will search in all graphs.
  We can repeat the \texttt{FROM} clause to query over multiple graphs in the
  same RDF store.

\begin{siderules}
\begin{verbatim}
SELECT ?s ?p ?o
FROM <graph-name>
FROM <another-graph-name>
WHERE { ?s ?p ?o }
\end{verbatim}
\end{siderules}

  In section \ref{sec:federated-querying} {\color{LinkGray}%
  `\nameref{sec:federated-querying}'} we will look at querying over multiple
  RDF stores.

\subsection{Exploring the structure of knowledge in a graph}


  Inside the \texttt{WHERE} clause of a SPARQL query we specify a graph
  pattern.  When the information in a graph is structured, there are only few
  predicates in comparison to the number of subjects and the number of objects.

\begin{siderules}
\begin{verbatim}
SELECT COUNT(DISTINCT ?s) AS ?subjects
       COUNT(DISTINCT ?p) AS ?predicates
       COUNT(DISTINCT ?o) AS ?objects
FROM <http://example>
WHERE { ?s ?p ?o }
\end{verbatim}
\end{siderules}

On a typical graph with data originating from \texttt{vcf2rdf}, this may yield
the following table:

\begin{table}[H]
  \begin{tabularx}{\textwidth}{ X X X }
    \headrow
    \textbf{subjects} & \textbf{predicates} & \textbf{objects}\\
    \evenrow
    \texttt{3011691} & \texttt{229} & \texttt{4000809}\\
  \end{tabularx}
  \caption{\small Results of the query to count the number of subjects,
    predicates, and objects in a graph.}
  \label{table:query-output-2}
\end{table}

  Therefore, one useful method of finding out which patterns exist in a
  graph is to look for predicates:

\begin{siderules}
\begin{verbatim}
SELECT DISTINCT ?predicate
FROM <http://example>
WHERE {
  ?subject ?predicate ?object .
}
\end{verbatim}
\end{siderules}

  Which may yield the following table:

\begin{table}[H]
  \begin{tabularx}{\textwidth}{ L }
    \headrow
    \textbf{predicate}\\
    \evenrow
    \texttt{http://biohackathon.org/resource/faldo\#position}\\
    \oddrow
    \texttt{http://biohackathon.org/resource/faldo\#reference}\\
    \evenrow
    \texttt{http://rdf.umcutrecht.nl/vcf2rdf/filename}\\
    \oddrow
    \texttt{http://rdf.umcutrecht.nl/vcf2rdf/foundIn}\\
    \evenrow
    \texttt{http://rdf.umcutrecht.nl/vcf2rdf/sample}\\
    \oddrow
    \texttt{http://rdf.umcutrecht.nl/vcf2rdf/VariantCall/ALT}\\
    \evenrow
    \texttt{http://rdf.umcutrecht.nl/vcf2rdf/VariantCall/FILTER}\\
    \oddrow
    $\ldots$\\
  \end{tabularx}
  \caption{\small Results of the query to list predicates.}
  \label{table:query-output-3}
\end{table}

\subsection{Listing samples and their originating files}

Using the knowledge we gained from exploring the predicates in a graph,
we can construct more insightful queries, like finding the names of the
samples and their originating filenames from the output of \texttt{vcf2rdf}:

\begin{siderules}
\begin{verbatim}
PREFIX vcf2rdf: <http://rdf.umcutrecht.nl/vcf2rdf/>

SELECT DISTINCT STRAFTER(STR(?sample), "Sample/") AS ?sample ?filename
FROM <graph-name>
WHERE {
  ?variant  vcf2rdf:sample    ?sample .
  ?sample   vcf2rdf:foundIn   ?origin .
  ?origin   vcf2rdf:filename  ?filename .
}
\end{verbatim}
\end{siderules}

Which may yield the following table:

\begin{table}[H]
  \begin{tabularx}{\textwidth}{ l L }
    \headrow
    \textbf{sample} & \textbf{filename}\\
    \evenrow
    \texttt{REF0047} & \texttt{/data/examples/TUMOR\_REF0047.annotated.vcf.gz}\\
    \oddrow
    \texttt{TUMOR0047} & \texttt{/data/examples/TUMOR\_REF0047.annotated.vcf.gz}\\
    \evenrow
    $\ldots$ & $\ldots$\\
  \end{tabularx}
  \caption{\small Results of the query to list samples and their originating
    filenames.}
  \label{table:query-output-4}
\end{table}

  Notice how most predicates for \texttt{vcf2rdf} in table
  \ref{table:query-output-3} start with
  \texttt{http://rdf.umcutrecht.nl/vcf2rdf/}.  In the above query, we used
  this to shorten the query.  We started the query by writing a \texttt{PREFIX}
  rule for \texttt{http://rdf.umcutrecht.nl/vcf2rdf/}, which we called
  \texttt{vcf2rdf:}.  This means that whenever we write \texttt{vcf2rdf:FOO}, the SPARQL endpoint interprets
  it as if we would write\\\texttt{<http://rdf.umcutrecht.nl/vcf2rdf/FOO>}.

  We will use more prefixes in the upcoming queries.  We can look up prefixes
  for common ontologies using \href{http://prefix.cc}{http://prefix.cc}.

\subsection{Listing samples, originated files, and number of variants}

Building on the previous query, and by exploring the predicates of a
\texttt{vcf2rdf:VariantCall}, we can construct the following query to
include the number of variants for each sample, in each file.

\begin{siderules}
\begin{verbatim}
PREFIX vcf2rdf: <http://rdf.umcutrecht.nl/vcf2rdf/>
PREFIX rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>

SELECT DISTINCT STRAFTER(STR(?sample), "Sample/") AS ?sample
       ?filename
       COUNT(DISTINCT ?variant) AS ?numberOfVariants

FROM <graph-name>
WHERE
{
  ?variant  rdf:type                vcf2rdf:VariantCall ;
            vcf2rdf:sample          ?sample ;
            vcf2rdf:originatedFrom  ?origin .

  ?origin   vcf2rdf:filename        ?filename .
}
\end{verbatim}
\end{siderules}

  Which may yield the following table:

  \begin{table}[H]
    \begin{tabularx}{\textwidth}{ l L l }
      \headrow
      \textbf{sample} & \textbf{filename} & \textbf{numberOfVariants}\\
      \evenrow
      \texttt{REF0047}   & \texttt{/data/examples/TUMOR\_REF0047.annotated.vcf.gz} & \texttt{1505712}\\
      \oddrow
      \texttt{TUMOR0047} & \texttt{/data/examples/TUMOR\_REF0047.annotated.vcf.gz} & \texttt{1505712}\\
      \evenrow
      $\ldots$ & $\ldots$ & $\ldots$\\
    \end{tabularx}
    \caption{\small Results of the query to list samples, their originated
      filenames, and the number of variant calls for each sample in a file.}
    \label{table:query-output-5}
  \end{table}

  By using \texttt{COUNT}, we can get the \texttt{DISTINCT} number of
  matching patterns for a variant call for a sample, originating from
  a distinct file.

\subsection{Retrieving all variants}

  When retrieving potentially large amounts of data, the \texttt{LIMIT}
  clause may come in handy to prototype a query until we are sure enough
  that the query answers the actual question we would like to answer.

  In the next example query, we will retrieve the sample name,
  chromosome, position, and the corresponding VCF \texttt{FILTER} field(s)
  from the database.

\begin{siderules}
\begin{verbatim}
PREFIX vcf2rdf: <http://rdf.umcutrecht.nl/vcf2rdf/>
PREFIX vc:      <http://rdf.umcutrecht.nl/vcf2rdf/VariantCall/>
PREFIX rdf:     <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX faldo:   <http://biohackathon.org/resource/faldo#>

SELECT DISTINCT ?variant ?sample ?chromosome ?position ?filter
FROM <graph-name>
WHERE
{
  ?variant  rdf:type                vcf2rdf:VariantCall ;
            vcf2rdf:sample          ?sample ;
            faldo:reference         ?chromosome ;
            faldo:position          ?position ;
            vc:FILTER               ?filter .
}
LIMIT 100
\end{verbatim}
\end{siderules}

  By limiting the result set to the first 100 rows, the query will return
  with an answer rather quickly.  Had we not set a limit to the number of
  rows, the query could have returned possibly a few million rows, which
  would obviously take longer to process.

\subsection{Retrieving variants with a specific mutation}

  Any property can be used to subset the results.  For example, we can
  look for occurrences of a \texttt{C} to \texttt{T} mutation in the positional
  range $202950000$ to $202960000$ on chromosome \texttt{2}, according to the
  \emph{GRCh37 (hg19)} reference genome with the following query:

\begin{siderules}
\begin{verbatim}
PREFIX rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX rdfs:  <http://www.w3.org/2000/01/rdf-schema#>
PREFIX faldo: <http://biohackathon.org/resource/faldo#>
PREFIX hg19:  <http://rdf.biosemantics.org/data/genomeassemblies/hg19#>
PREFIX v:     <http://rdf.umcutrecht.nl/vcf2rdf/>
PREFIX vc:    <http://rdf.umcutrecht.nl/vcf2rdf/VariantCall/>
PREFIX seq:   <http://rdf.umcutrecht.nl/vcf2rdf/Sequence/>

SELECT COUNT(DISTINCT ?variant) AS ?occurrences ?sample
FROM <http://example>
WHERE {
  ?variant  rdf:type         v:VariantCall .
  ?variant  rdf:type         ?genotype .
  ?variant  v:sample         ?sample .
  ?variant  vc:REF           seq:C .
  ?variant  vc:ALT           seq:T .
  ?variant  faldo:reference  hg19:chr2 .
  ?variant  faldo:position   ?position .

  FILTER (?position >= 202950000)
  FILTER (?position <= 202960000)

  # Exclude variants that actually don't deviate from hg19.
  FILTER (?genotype != v:HomozygousReferenceGenotype)
}
LIMIT 2
\end{verbatim}
\end{siderules}

Which may yield the following table:

\begin{table}[H]
  \begin{tabularx}{\textwidth}{ l L }
    \headrow
    \textbf{occurrences} & \textbf{sample}\\
    \evenrow
    \texttt{5} & \texttt{http://rdf.umcutrecht.nl/vcf2rdf/Sample/REF0047}\\
    \oddrow
    \texttt{5} & \texttt{http://rdf.umcutrecht.nl/vcf2rdf/Sample/TUMOR0047}\\
  \end{tabularx}
  \caption{\small Query results of the above query.}
  \label{table:query-output-6}
\end{table}

\section{Federated querying}
\label{sec:federated-querying}

  Now that we've seen local queries, there's only one more construct we need to
  know to combine this with remote SPARQL endpoints: the \texttt{SERVICE}
  construct.

  For the next example, we will use the \href{http://www.ebi.ac.uk/rdf/services/sparql}%
  {public SPARQL endpoint hosted by EBI}.

\subsection{Get an overview of Biomodels (from ENSEMBL)}

\begin{siderules}
\begin{verbatim}
PREFIX sbmlrdf: <http://identifiers.org/biomodels.vocabulary#>
PREFIX sbmldb:  <http://identifiers.org/biomodels.db/>

SELECT ?speciesId ?name {
  SERVICE <http://www.ebi.ac.uk/rdf/services/sparql/> {
    sbmldb:BIOMD0000000001 sbmlrdf:species ?speciesId .
    ?speciesId sbmlrdf:name ?name
  }
}
\end{verbatim}
\end{siderules}

Which may yield the following table:

\begin{table}[H]
  \begin{tabularx}{\textwidth}{ l L }
    \headrow
    \textbf{speciesId} & \textbf{name}\\
    \evenrow
    \texttt{http://identifiers.org/biomodels.db/BIOMD0000000001\#\_000003} & \texttt{BasalACh2}\\
    \oddrow
    \texttt{http://identifiers.org/biomodels.db/BIOMD0000000001\#\_000004} & \texttt{IntermediateACh}\\
    \evenrow
    \texttt{http://identifiers.org/biomodels.db/BIOMD0000000001\#\_000005} & \texttt{ActiveACh}\\
    \oddrow
    \texttt{http://identifiers.org/biomodels.db/BIOMD0000000001\#\_000006} & \texttt{Active}\\
    \evenrow
    \texttt{http://identifiers.org/biomodels.db/BIOMD0000000001\#\_000007} & \texttt{BasalACh}\\
    \oddrow
    $\ldots{}$ & $\ldots{}$\\
  \end{tabularx}
  \caption{\small Query results of the above query.}
  \label{table:query-output-7}
\end{table}

\chapter{Programming in R}
\label{chap:programming}

\section{Using SPARQL with R}
\label{sec:sparql-with-r}

  Before we can start, we need to install the \texttt{SPARQL} package from
  \href{https://cran.r-project.org/web/packages/SPARQL/index.html}{CRAN}.

\begin{siderules}
\begin{verbatim}
install.packages('SPARQL')
\end{verbatim}
\end{siderules}

  Once we're set up, we can query like so:

\begin{siderules}
\begin{verbatim}
# Load the library
library('SPARQL')

# Define the endpoint to query.
endpoint <- "http://localhost:8890/sparql"

# Define the actual query to run.
query <- "PREFIX vcf2rdf: <http://rdf.umcutrecht.nl/vcf2rdf/>
PREFIX vc:    <http://rdf.umcutrecht.nl/vcf2rdf/VariantCall/>
PREFIX rdf:   <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
PREFIX faldo: <http://biohackathon.org/resource/faldo#>

SELECT DISTINCT ?variant ?sample ?chromosome ?position ?filter
FROM <graph-name>
WHERE
{
  ?variant  rdf:type                vcf2rdf:VariantCall ;
            vcf2rdf:sample          ?sample ;
            faldo:reference         ?chromosome ;
            faldo:position          ?position ;
            vc:FILTER               ?filter .
}
LIMIT 10";

# Run the query
query_data <- SPARQL (endpoint, query)

# Put the results (a data frame) in a separate variable.
query_results <- query_data$results
\end{verbatim}
\end{siderules}

\end{document}
